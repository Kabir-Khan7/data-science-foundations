{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0562355-49b8-413a-8354-6032680505d7",
   "metadata": {},
   "source": [
    "# Data Types & Broadcasting in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce2222e-3a56-43c7-9afb-a1df9f2fe56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da62793-f245-4a1d-9e95-ca8715c61a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(0,101)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2c614b9-6c71-406c-abe6-26eb2f35f89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e20fbe72-0db0-4042-b332-794e043bb43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "        22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "        33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "        44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "        55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "        66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "        77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "        88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "        99., 100.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = arr\n",
    "arr1.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc00dbce-2136-401f-96ca-4241f81895fe",
   "metadata": {},
   "source": [
    "## Downcasting to Save Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9101165a-ccc1-4d61-80e2-0a77bfbe9bb4",
   "metadata": {},
   "source": [
    "The core idea of downcasting is to optimize memory by reducing the bit size of an array's data type, such as converting from $\\text{int64}$ (8 bytes) to $\\text{int32}$ (4 bytes). This technique is crucial when a dataset's maximum value can be safely represented by a smaller type. By ensuring the data type's memory footprint is just large enough for the range of values, you can save significant memory. This reduction in memory usage directly translates into faster data loading and improved processing speeds, as more data fits into the CPU's cache. This optimization is achieved without compromising data integrity, provided no values exceed the new, smaller type's capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a1d6db-95b0-4bf4-b75f-dc1aaec6de4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100000 200000 300000]\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "arr_large = np.array([100000, 200000, 300000], dtype=np.int64)\n",
    "arr_small = arr_large.astype(np.int32) # Downcastting to small\n",
    "print(arr_small)\n",
    "print(arr_small.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a71456-6233-4bb6-b429-73c48e663d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small: 12\n",
      "Large: 24\n"
     ]
    }
   ],
   "source": [
    "print(f\"Small: {arr_small.nbytes}\")\n",
    "print(f\"Large: {arr_large.nbytes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd8dfe23-4e94-4c29-92ff-a3e832ddc034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4  9 16 25]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1,2,3,4,5])\n",
    "result = arr ** 2 #Vectorized Operations\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3845031-1c42-4088-890b-13a9d3667007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 14, 19, 26, 35])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf06a49-d7a2-4d23-85ea-7321cb34ec76",
   "metadata": {},
   "source": [
    "## Broadcasting in 2D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ad4a65-ddcd-4625-8ab2-a309d934f900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4 6]\n",
      " [5 7 9]]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([[1,2,3], [4,5,6]])\n",
    "arr2 = np.array([1,2,3])\n",
    "result1 = arr1 + arr2\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4946a-bd4f-4b5f-bd23-d26e8451635a",
   "metadata": {},
   "source": [
    "## Normalization Data Using Broadcasting \n",
    "\n",
    "Imagine we have a dataset where each row represents a sample and each column represent a feature. You can normalize the data by subtracting the mean of each column and dividing by the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450cf3f2-8d02-4c95-a077-1e81d7656a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [[10 20 30]\n",
      " [15 25 35]\n",
      " [20 30 40]\n",
      " [25 35 45]\n",
      " [30 40 50]]\n",
      "Mean of the data: [20. 30. 40.]\n",
      "Std Deviation of the data: [7.07106781 7.07106781 7.07106781]\n",
      "Normalized Data: [[[-1.41421356 -1.41421356 -1.41421356]\n",
      "  [-0.70710678 -0.70710678 -0.70710678]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.70710678  0.70710678  0.70710678]\n",
      "  [ 1.41421356  1.41421356  1.41421356]]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[10,20,30],\n",
    "                 [15,25,35],\n",
    "                 [20,30,40],\n",
    "                 [25,35,45],\n",
    "                 [30,40,50]])\n",
    "\n",
    "mean = data.mean(axis=0)\n",
    "std = data.std(axis=0)\n",
    "\n",
    "print(f\"Data: {data}\")\n",
    "print(f\"Mean of the data: {mean}\")\n",
    "print(f\"Std Deviation of the data: {std}\")\n",
    "\n",
    "normalized_data = [data - mean] / std\n",
    "print(f\"Normalized Data: {normalized_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229299b0-74af-4109-a98d-3916d57b166a",
   "metadata": {},
   "source": [
    "# Summary: \n",
    "Broadcasting in NumPy allows arrays of different shapes to work together during arithmetic operations without needing explicit loops or extra memory. Python loops are slow because they process elements one at a time, while NumPyâ€™s underlying C code performs operations on entire blocks of data at once. Broadcasting uses this vectorization to apply operations across large arrays instantly, making computations highly efficient. In real-world data science, broadcasting is essential for tasks like normalizing datasets, where you subtract the mean and divide by the standard deviation across millions of values without copying data. This lets you transform large datasets quickly while keeping memory usage and performance optimized."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
